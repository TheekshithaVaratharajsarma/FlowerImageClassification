{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15d3aac8-61d1-4769-9466-ac1581aa374b",
   "metadata": {},
   "source": [
    "# Implementing CNNs - Assignment 2\n",
    "\n",
    "### Group 5\n",
    "- Theekshitha Varatharajsarma\n",
    "- Dhilky Nonis\n",
    "- Mohamed Sabath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8b00bf-103e-40cc-a193-595776f17c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccfc869-55a4-4608-b93a-a1dd34aa8fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Architecture\n",
    "class FlowerRecognitionModel:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3), input_shape=input_shape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=(3, 3)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(150))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        model.summary()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19676757-de9b-4b93-bed9-09236a97ad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "no_epochs = 25\n",
    "batch_size = 25\n",
    "valid_split = 0.2\n",
    "verbose = 1\n",
    "optimizer = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fab2cd-e574-4bf9-95ec-4d1d7604e62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image and class information\n",
    "img_rows, img_cols = 224, 224\n",
    "no_classes = 5 \n",
    "input_shape = (img_rows, img_cols, 3)  #RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44816c7-80d5-47a5-bc27-c1f9f0140378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the path to data\n",
    "data_dir = 'data'\n",
    "base_dir = 'flower_split'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d9a823-fe2f-44c2-9a52-8e09a66dd9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating base directory & train, test directories\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf93b96-a107-41c4-b34d-0ce050a2e1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test sets\n",
    "for flower_class in os.listdir(data_dir):\n",
    "    class_dir = os.path.join(data_dir, flower_class)\n",
    "    images = os.listdir(class_dir)\n",
    "    train_images, test_images = train_test_split(images, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Moving images to train directory\n",
    "    for img in train_images:\n",
    "        src = os.path.join(class_dir, img)\n",
    "        dest = os.path.join(train_dir, flower_class, img)\n",
    "        os.makedirs(os.path.dirname(dest), exist_ok=True)\n",
    "        shutil.copy(src, dest)\n",
    "\n",
    "    # Moving images to test directory\n",
    "    for img in test_images:\n",
    "        src = os.path.join(class_dir, img)\n",
    "        dest = os.path.join(test_dir, flower_class, img)\n",
    "        os.makedirs(os.path.dirname(dest), exist_ok=True)\n",
    "        shutil.copy(src, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "339881c7-5c3e-425b-abde-f4e2dc3ba3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation to increase diversity\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051d8dce-cfb6-46f7-8f62-b1de82ac797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building and compiling the model\n",
    "model = FlowerRecognitionModel.build(input_shape=input_shape, classes=no_classes)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea91dc1d-75dc-4440-ae49-fee486c63bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using flow_from_directory to load and preprocess images\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7878c99-24ec-45c8-9f75-02d1d7efc2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=no_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    verbose=verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dff57d-cfd9-4711-9a2a-7530f3b83316",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = history.history['loss']\n",
    "train_accuracy = history.history['accuracy']\n",
    "\n",
    "# Evaluating the model on the test set\n",
    "score = model.evaluate(validation_generator, steps=validation_generator.samples // batch_size, verbose=verbose)\n",
    "test_loss = score[0]\n",
    "test_accuracy = score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f4e164-f6f8-42a9-b32a-f16841761cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the history in separate text files\n",
    "\n",
    "with open('training_history.txt', 'w') as f:\n",
    "    formatted_history = {key: [round(value, 4) for value in values] for key, values in history.history.items()}\n",
    "    f.write(str(formatted_history))\n",
    "\n",
    "with open('evaluation_output.txt', 'w') as f:\n",
    "    f.write(f'Test Loss: {test_loss}\\nTest Accuracy: {test_accuracy}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaaebb6-4b5c-4a07-b03d-589da7c0d5b7",
   "metadata": {},
   "source": [
    "## Variation 1\n",
    "\n",
    "Added Dropout Layers. The changes made are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1828a8ba-04c5-48c8-8679-5f87b52b8cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerRecognitionModelWithDropout:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes,l2_regularization=0.01):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3), input_shape=input_shape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=(3, 3)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(150))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        model.summary()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32a2e78-bb2b-4fbc-80d8-7c3c646e477a",
   "metadata": {},
   "source": [
    "## Variation 2\n",
    "\n",
    "Increased the depth of the model by adding another Con2D Layer with dropout\n",
    "\n",
    "The changes made are in the code chunk below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cef7c17d-f5d8-4541-b579-8aa596915996",
   "metadata": {},
   "outputs": [],
   "source": [
    "class flower_recognition_model_var2:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3), input_shape=input_shape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=(3, 3)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(128, kernel_size=(3, 3)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(150))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        model.summary()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a97adfc-de2c-4acc-82f9-9dd70e4fa5c0",
   "metadata": {},
   "source": [
    "## Variation 3\n",
    "\n",
    "With the added Conv2D layer and dropout layers, changed the hyperparameters (Hyperparameter tuning)\n",
    "\n",
    "Here, I increased the epochs from 25 to 40 and decreased the batchsize from 25 to 20.\n",
    "\n",
    "The changes below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b046c1c-c093-423f-9d8b-ed2e5b05740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class flower_recognition_model_var3:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3), input_shape=input_shape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=(3, 3)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(128, kernel_size=(3, 3)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(150))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "# Hyperparameters\n",
    "no_epochs = 40\n",
    "batch_size = 20\n",
    "valid_split = 0.2\n",
    "verbose = 1\n",
    "optimizer = Adam()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
